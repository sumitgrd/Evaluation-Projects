{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d45b515",
   "metadata": {},
   "source": [
    "Avocado Project\n",
    "Project Description\n",
    "This data was downloaded from the Hass Avocado Board website in May of 2018 & compiled into a single CSV. \n",
    "The table below represents weekly 2018 retail scan data for National retail volume (units) and price. Retail scan data comes directly from retailers’ cash registers based on actual retail sales of Hass avocados. \n",
    "Starting in 2013, the table below reflects an expanded, multi-outlet retail data set. Multi-outlet reporting includes an aggregation of the following channels: grocery, mass, club, drug, dollar and military. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. \n",
    "The Product Lookup codes (PLU’s) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.\n",
    "Some relevant columns in the dataset:\n",
    "•\tDate - The date of the observation\n",
    "•\tAveragePrice - the average price of a single avocado\n",
    "•\ttype - conventional or organic\n",
    "•\tyear - the year\n",
    "•\tRegion - the city or region of the observation\n",
    "•\tTotal Volume - Total number of avocados sold\n",
    "•\t4046 - Total number of avocados with PLU 4046 sold\n",
    "•\t4225 - Total number of avocados with PLU 4225 sold\n",
    "•\t4770 - Total number of avocados with PLU 4770 sold\n",
    "\n",
    "Inspiration /Label \n",
    "The dataset can be seen in two angles to find the region and find the average price .\n",
    "Task: One of Classification and other of Regression\n",
    "Do both tasks in the same .ipynb file and submit at single file. \n",
    "\n",
    "Dataset Link-\n",
    "•\thttps://github.com/FlipRoboTechnologies/ML_-Datasets/blob/main/Avocado/avocado.csv.zip\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all library\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warning \n",
    "warning.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score,classification_repoprt,confusion_matrix,roc_auc_score,roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.navie_bayes import GaussianNB\n",
    "from sklearn.neighbours import KNeighboursClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecissionTreeClassifier\n",
    "from sklearn.ensamble import AdaBoostClassifier,gradient_boosting\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selectoion import cross_val_score,train_test_split,GridSearchCV\n",
    "from sklearn.external import joblib\n",
    "from sklearn.decomostion import PCA\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching data into variable \n",
    "df = pd.read_csv(\"c://user//sumit//Desktop//Datatrained//Data sets//Project//anaconda.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we drop index column becuase it just kind of id which have effect an datset\n",
    "df.drop('index'inplace'=True,axis= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the total rows and total total columns\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96152b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values using heatmap\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the mean of price at each year of organic type of avacodo\n",
    "organic.groupby('year')['AveragePrice'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding how much type avacodo is well in last 4 year\n",
    "df.groupby('year')['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dcdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking ratio of year and price that which year had max average price \n",
    "sns.barplot(x= \"year\" , y = \"AveragePrice\" ,data=df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6abb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking ratio of month and price that which year had max average price \n",
    "sns.barplot(x= \"month\" , y = \"AveragePrice\" ,data=df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=6,10))\n",
    "sns.lineplot(x=\"Month\", y=\"AveragePrice\", hue='type',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea396258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting histogram for univariate analysis and checking the Noraml Distribution \n",
    "df.hist(figsize=(20,20),grid = Tree,layout = (4,4),bins= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0526fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d37df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the skew less than or eual to 0.55 for better predicton and plotting Noramal distribution\n",
    "skew=('Total volume','PLU_4046','PLU'_4770','Total Bags',\n",
    "      'Small Bags''Large Bags','XLarge Bags')\n",
    "for col in skwe:\n",
    "    if df.skew().loc[col]>0.55:\n",
    "        df[col] =np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc20811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the boxplot odf each column to check the outliers \n",
    "df.plot(kind='box',subplots = True,layout=(4,5),figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b694e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the zscore\n",
    "z = np.abs(zsore(df))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac244fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresold = 3\n",
    "print(np.where(z<3))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the value to df_new which are less the threshold value and removing the outliers\n",
    "df_new = df[(z<3).all(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df_new.shape)\n",
    "df = df_new\n",
    "print('Shape after removing ourliers'df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the co relation of all column to each other\n",
    "df_cor_df.corr()\n",
    "plt.figure(figsize=(10,25))\n",
    "sns.heatmap(df_cof,annot=True)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f550895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now by using multiple Algorithm we are calculating the best Algo which suit best for our data set\n",
    "\n",
    "model = [DecisionTreeRegressor(),KNeighboursRegressor(),AdaboostRegressor(),LinearRegression(),GradientBoostingRegressor()]\n",
    "max_r2_score = 0\n",
    "for r_state in range(40,90):\n",
    "    train_x,test_x,train,test_y = train_test_split(x,y,random_state = r_state,test_size = 0.33)\n",
    "    for i in model:\n",
    "        i.fit(train_x,train_y)\n",
    "        pre = i.predict(test_x)\n",
    "        r2_sc = r2_score(test_y,pre)\n",
    "        print(\"R2 score correspond to random state \" ,r_state, \"is\", r2_sc)\n",
    "        if r2_sc> max_r2_score:\n",
    "            max_r2_score=r2_sc\n",
    "            final_state = r_state\n",
    "            final_model = i \n",
    "            \n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"max R2 score correspond to random state \",final_state, \"is\",max_r2_score,\"and model is\",final_model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the best parameter for predication of KNeighboursRegrssor Algo using GridSearchCV\n",
    "train_test,text_x,train_y,test_y = train_test_split(x,y,random_state = 80,test_size = 0.33)\n",
    "KN = KNeighboursRegressor()\n",
    "parametres={'n_neighbours' : range(1,30)}\n",
    "gridsearch=GridSearchCV(LA,parameters)\n",
    "gridsearch.fit(train_x,train_y)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN _ KNeughboursRegressor(n_neighbours_2)\n",
    "KNN.fit(train x,train y )\n",
    "pred _ KNN.predict(test_x)\n",
    "r2_sc = r2_score(test_y,pred)\n",
    "print(\"R2 Score :\",r2_sc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error: ',mean_absolute_error(test_y,pred))\n",
    "print('Mean squared Error:, mean_squared_error(test_y,pred))\n",
    "print('Root Mean Absolute Error:',np.sqrt(mean_absolute_error(test_y,ptred)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the diff between actual and predicted value using graph\n",
    "plt.scatter(x=test_y.y=pred)\n",
    "plt.xlabel('Y_test')\n",
    "plt.ylabel('Predicted_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e159079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library for classification predication\n",
    "from skleran.matrics import accuracy_score,Classification_report,confusion_matrix,roc_auc_score,roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.navie_bayes import MultinomialaNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecissionTreeClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d897b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the value of x and y for training and testing phase \n",
    "X_c = df.drop(column=['region','Date'])\n",
    "y_c = df[[\"region\"]]\n",
    "print(x_c.shape)\n",
    "print(y_c.shape)\n",
    "\n",
    "(17525,12)\n",
    "(17525,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe092cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarlize the value of x so that mean will 0 and so will become1 ,and make the data as normal distributed\n",
    "Sc = StndardScaler()\n",
    "Sc.fit_transform(x_c)\n",
    "x_c = pd.DataFrame(x_c,columns=x_c.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa780ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
